# ğŸš€ GuÃ­a de Deployment Automatizado - Coarlumini en K3s

Esta guÃ­a te llevarÃ¡ paso a paso para desplegar automÃ¡ticamente la aplicaciÃ³n Coarlumini en un cluster K3s con autoscaling en Google Cloud Platform.

## âœ… Cambios Realizados para K3s

Los siguientes archivos han sido actualizados para compatibilidad con K3s:

### **Manifiestos de Kubernetes**
- âœ… `coarlumini/k8s/03-database-pvc.yaml` - `storageClassName: local-path`
- âœ… `coarlumini/k8s/07-backend-pvc.yaml` - `storageClassName: local-path`
- âœ… `coarlumini/k8s/10-frontend-pvc.yaml` - `storageClassName: local-path`

### **Scripts de InicializaciÃ³n**
- âœ… `scripts/k3s-server-init.sh` - Descarga imÃ¡genes Docker automÃ¡ticamente en el master
- âœ… `scripts/k3s-agent-init.sh` - Descarga imÃ¡genes Docker automÃ¡ticamente en workers
- âœ… `main.tf` - Service Account con permisos para Artifact Registry

### **Nuevos Scripts**
- âœ… `scripts/validate-setup.sh` - Valida que todo estÃ© configurado correctamente

## ğŸ“‹ Prerrequisitos

Antes de comenzar, asegÃºrate de tener:

### 1. Herramientas Instaladas
```bash
# Verificar instalaciones
gcloud --version
docker --version
terraform --version  # o tofu --version
```

### 2. Cuenta de Google Cloud
- Proyecto de GCP creado
- FacturaciÃ³n habilitada
- APIs necesarias habilitadas

### 3. AutenticaciÃ³n
```bash
# Autenticar con gcloud
gcloud auth login

# Configurar proyecto
gcloud config set project TU-PROJECT-ID

# Autenticar Docker con GCR
gcloud auth configure-docker gcr.io

# AutenticaciÃ³n para Terraform
gcloud auth application-default login
```

## ğŸ¯ Deployment en 5 Pasos

### **Paso 1: Validar Setup**

```bash
cd ~/Documents/Universidad/5B_CloudComputing/autoscaling-demo

# Ejecutar validaciÃ³n
./scripts/validate-setup.sh
```

Este script verifica:
- âœ… Herramientas instaladas (gcloud, docker, terraform)
- âœ… AutenticaciÃ³n de gcloud
- âœ… Estructura de archivos del proyecto
- âœ… Manifiestos de Kubernetes correctos
- âœ… Dockerfiles presentes
- âœ… APIs de GCP habilitadas

**Si hay errores, corrÃ­gelos antes de continuar.**

### **Paso 2: Configurar Variables**

```bash
# Copiar archivo de ejemplo (si no existe)
cp terraform.tfvars.example terraform.tfvars

# Editar con tus valores
nano terraform.tfvars
```

**ConfiguraciÃ³n mÃ­nima requerida:**
```hcl
project_id = "tu-proyecto-gcp"
region     = "us-central1"
```

**ConfiguraciÃ³n recomendada:**
```hcl
project_id = "tu-proyecto-gcp"
region     = "us-central1"

# Tipos de mÃ¡quinas
k3s_server_machine_type = "e2-medium"  # Master: 2 vCPUs, 4GB RAM
agent_machine_type      = "e2-small"   # Workers: 2 vCPUs, 2GB RAM

# Autoscaling
min_replicas = 2  # MÃ­nimo de workers
max_replicas = 5  # MÃ¡ximo de workers
cpu_target   = 0.6  # 60% CPU para escalar

# Deployment automÃ¡tico
enable_auto_deploy = true
deploy_wait_time   = 180  # Segundos de espera antes de desplegar
```

### **Paso 3: Habilitar APIs de GCP**

```bash
# Habilitar todas las APIs necesarias
gcloud services enable compute.googleapis.com \
  storage-api.googleapis.com \
  containerregistry.googleapis.com \
  artifactregistry.googleapis.com \
  --project=tu-proyecto-gcp
```

### **Paso 4: Inicializar Terraform**

```bash
# Inicializar (solo la primera vez)
terraform init

# Ver plan de ejecuciÃ³n
terraform plan -var-file=terraform.tfvars
```

### **Paso 5: Desplegar Todo**

```bash
# Â¡UN SOLO COMANDO DESPLIEGA TODO!
terraform apply -var-file=terraform.tfvars
```

Cuando pregunte `Do you want to perform these actions?`, escribe `yes` y presiona Enter.

## â±ï¸ Â¿QuÃ© Sucede AutomÃ¡ticamente?

El deployment automÃ¡tico ejecuta estos pasos en orden:

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ 1. INFRAESTRUCTURA (2-3 min)           â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ - Red VPC                               â”‚
â”‚ - Subredes                              â”‚
â”‚ - Reglas de Firewall                    â”‚
â”‚ - Service Account                       â”‚
â”‚ - Cloud Storage bucket                  â”‚
â”‚ - Load Balancer                         â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
            â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ 2. K3S MASTER SERVER (3-4 min)         â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ - Instancia e2-medium                   â”‚
â”‚ - Instala Docker                        â”‚
â”‚ - Instala K3s server                    â”‚
â”‚ - Instala Helm & nginx-ingress          â”‚
â”‚ - Descarga manifiestos desde GCS        â”‚
â”‚ - DESCARGA IMÃGENES DOCKER DE GCR       â”‚
â”‚ - Configura namespace y secrets         â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
            â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ 3. K3S WORKER NODES (2-3 min)          â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ - 2-5 instancias e2-small               â”‚
â”‚ - Instala Docker                        â”‚
â”‚ - Instala K3s agent                     â”‚
â”‚ - Se une al cluster                     â”‚
â”‚ - DESCARGA IMÃGENES DOCKER DE GCR       â”‚
â”‚ - Configura health checks               â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
            â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ 4. BUILD IMÃGENES DOCKER (5-7 min)     â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ - Construye coarlumini-database         â”‚
â”‚ - Construye coarlumini-backend          â”‚
â”‚ - Construye coarlumini-frontend         â”‚
â”‚ - Sube a gcr.io/PROJECT_ID/             â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
            â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ 5. DEPLOY A KUBERNETES (3-5 min)       â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ - Despliega MySQL database              â”‚
â”‚ - Despliega Laravel backend             â”‚
â”‚ - Despliega Vue.js frontend             â”‚
â”‚ - Configura servicios NodePort          â”‚
â”‚ - Configura HPA (autoscaling)           â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
            â†“
        âœ… LISTO
   (12-15 minutos total)
```

## ğŸ‰ Acceder a la AplicaciÃ³n

Una vez completado el deployment:

```bash
# Ver outputs de Terraform
terraform output

# URLs de acceso
terraform output access_urls
```

ObtendrÃ¡s dos formas de acceder:

### **OpciÃ³n 1: Load Balancer (Recomendado)**
```
http://<LOAD_BALANCER_IP>
```

### **OpciÃ³n 2: Directo al Servidor K3s**
```
http://<SERVER_IP>:30080
```

## ğŸ” Verificar el Deployment

### **SSH al Servidor K3s**

```bash
# Desde tu mÃ¡quina local
gcloud compute ssh k3s-master-server --zone=us-central1-a --project=tu-proyecto-gcp

# Convertirse en root
sudo su -

# Ver nodos del cluster
kubectl get nodes

# Ver pods de Coarlumini
kubectl get pods -n coarlumini

# Ver servicios
kubectl get svc -n coarlumini

# Ver todos los recursos
kubectl get all -n coarlumini
```

### **Verificar que las ImÃ¡genes EstÃ¡n en los Nodos**

```bash
# En el servidor master
docker images | grep coarlumini

# En un worker (conectarse primero)
gcloud compute ssh k3s-agent-xxx --zone=us-central1-a
docker images | grep coarlumini
```

DeberÃ­as ver 3 imÃ¡genes:
```
gcr.io/tu-proyecto/coarlumini-database    latest
gcr.io/tu-proyecto/coarlumini-backend     latest
gcr.io/tu-proyecto/coarlumini-frontend    latest
```

### **Ver Logs de los Pods**

```bash
# Logs del database
kubectl logs -l app=coarlumini-database -n coarlumini -f

# Logs del backend
kubectl logs -l app=coarlumini-backend -n coarlumini -f

# Logs del frontend
kubectl logs -l app=coarlumini-frontend -n coarlumini -f
```

## ğŸ”§ Comandos Ãštiles

### **Estado del Cluster**

```bash
# Ver nodos
kubectl get nodes -o wide

# Ver pods en tiempo real
watch kubectl get pods -n coarlumini -o wide

# Ver PVCs (deben estar Bound)
kubectl get pvc -n coarlumini

# Ver eventos
kubectl get events -n coarlumini --sort-by='.lastTimestamp'
```

### **Escalar Manualmente**

```bash
# Escalar pods del backend
kubectl scale deployment coarlumini-backend -n coarlumini --replicas=3

# Ver HPA (Horizontal Pod Autoscaler)
kubectl get hpa -n coarlumini

# Describir HPA
kubectl describe hpa coarlumini-backend -n coarlumini
```

### **Reiniciar Componentes**

```bash
# Reiniciar backend
kubectl rollout restart deployment/coarlumini-backend -n coarlumini

# Ver progreso
kubectl rollout status deployment/coarlumini-backend -n coarlumini

# Reiniciar frontend
kubectl rollout restart deployment/coarlumini-frontend -n coarlumini
```

### **Redesplegar AplicaciÃ³n**

Si solo quieres redesplegar la aplicaciÃ³n (sin recrear infraestructura):

```bash
# OpciÃ³n 1: Desde tu mÃ¡quina local
cd autoscaling-demo
export PROJECT_ID="tu-proyecto-gcp"
export K3S_SERVER_NAME="k3s-master-server"
export ZONE="us-central1-a"

# Reconstruir imÃ¡genes
./scripts/build-and-push.sh

# Redesplegar
./scripts/deploy-to-k3s.sh

# OpciÃ³n 2: Desde el servidor K3s
gcloud compute ssh k3s-master-server --zone=us-central1-a
sudo /root/deploy-coarlumini.sh
```

## ğŸ› SoluciÃ³n de Problemas

### **Problema: Pods en ImagePullBackOff**

**Causa:** Las imÃ¡genes no se descargaron en los nodos.

**SoluciÃ³n:**
```bash
# Conectarse al nodo afectado
gcloud compute ssh <node-name> --zone=us-central1-a

# Autenticar Docker
gcloud auth configure-docker gcr.io

# Descargar imÃ¡genes manualmente
docker pull gcr.io/tu-proyecto/coarlumini-database:latest
docker pull gcr.io/tu-proyecto/coarlumini-backend:latest
docker pull gcr.io/tu-proyecto/coarlumini-frontend:latest

# Reiniciar pods
kubectl delete pod -l app=coarlumini-frontend -n coarlumini
```

### **Problema: PVCs en Pending**

**Causa:** StorageClass incorrecto o no existe.

**SoluciÃ³n:**
```bash
# Verificar StorageClass
kubectl get storageclass

# Crear si no existe
cat <<EOF | kubectl apply -f -
apiVersion: storage.k8s.io/v1
kind: StorageClass
metadata:
  name: local-path
  annotations:
    storageclass.kubernetes.io/is-default-class: "true"
provisioner: rancher.io/local-path
volumeBindingMode: WaitForFirstConsumer
reclaimPolicy: Delete
EOF

# Eliminar y recrear PVCs
kubectl delete pvc --all -n coarlumini
kubectl apply -f /root/k8s-manifests/03-database-pvc.yaml
kubectl apply -f /root/k8s-manifests/07-backend-pvc.yaml
kubectl apply -f /root/k8s-manifests/10-frontend-pvc.yaml
```

### **Problema: Backend en Init:0/1**

**Causa:** Esperando a que la database estÃ© lista.

**SoluciÃ³n:**
```bash
# Ver logs del init container
POD_NAME=$(kubectl get pods -n coarlumini -l app=coarlumini-backend -o jsonpath='{.items[0].metadata.name}')
kubectl logs $POD_NAME -n coarlumini -c init-app

# Verificar que database estÃ¡ running
kubectl get pods -l app=coarlumini-database -n coarlumini

# Verificar servicio de database
kubectl get svc coarlumini-database-service -n coarlumini

# Test de conectividad
kubectl run -it --rm debug --image=busybox --restart=Never -n coarlumini -- nc -zv coarlumini-database-service 3306
```

### **Problema: No puedo acceder desde el navegador**

**Causa:** Puerto no abierto en el firewall.

**SoluciÃ³n:**
```bash
# Verificar regla de firewall
gcloud compute firewall-rules describe web-firewall --project=tu-proyecto-gcp

# Verificar tags de la instancia
gcloud compute instances describe k3s-master-server \
  --zone=us-central1-a \
  --format="get(tags.items)"

# Test desde el servidor
curl -I http://localhost:30080
```

## ğŸ§¹ Limpiar Recursos

### **Eliminar Solo la AplicaciÃ³n**

```bash
# SSH al servidor
gcloud compute ssh k3s-master-server --zone=us-central1-a
sudo kubectl delete namespace coarlumini
```

### **Eliminar Toda la Infraestructura**

```bash
# Desde tu mÃ¡quina local
cd autoscaling-demo
terraform destroy -var-file=terraform.tfvars
```

**ADVERTENCIA:** Esto eliminarÃ¡:
- âŒ Todas las instancias (master + workers)
- âŒ Load Balancer
- âŒ Discos persistentes (se perderÃ¡n los datos)
- âŒ ImÃ¡genes en GCR (se mantienen)
- âŒ Cloud Storage bucket

## ğŸ’° EstimaciÃ³n de Costos

Con la configuraciÃ³n por defecto en `us-central1`:

| Recurso | EspecificaciÃ³n | Costo/mes |
|---------|---------------|-----------|
| K3s Master | 1x e2-medium (siempre activo) | ~$24 |
| K3s Workers | 2-5x e2-small (autoscaling) | ~$24-60 |
| Load Balancer | HTTP Global | ~$18 |
| Discos | 50GB + 30GB Ã— workers | ~$10-20 |
| Egreso red | Variable segÃºn uso | ~$5-10 |
| **TOTAL** | | **~$81-132/mes** |

### **Reducir Costos para Desarrollo**

```hcl
# En terraform.tfvars
min_replicas            = 1
max_replicas            = 2
k3s_server_machine_type = "e2-small"
agent_machine_type      = "e2-micro"  # MÃ­nimo absoluto
```

Costo reducido: **~$40-50/mes**

## ğŸ“š Referencias

- [DocumentaciÃ³n de K3s](https://docs.k3s.io/)
- [Terraform GCP Provider](https://registry.terraform.io/providers/hashicorp/google/latest/docs)
- [GCE Autoscaling](https://cloud.google.com/compute/docs/autoscaler)
- [Kubernetes Docs](https://kubernetes.io/docs/)
- [Google Container Registry](https://cloud.google.com/container-registry/docs)

## ğŸ“ Arquitectura del Proyecto

```
autoscaling-demo/
â”œâ”€â”€ main.tf                    # Infraestructura principal
â”œâ”€â”€ variables.tf               # Variables configurables
â”œâ”€â”€ outputs.tf                 # Outputs (IPs, URLs, comandos)
â”œâ”€â”€ terraform.tfvars           # TU configuraciÃ³n
â”œâ”€â”€ scripts/
â”‚   â”œâ”€â”€ validate-setup.sh      # âœ¨ ValidaciÃ³n pre-deployment
â”‚   â”œâ”€â”€ k3s-server-init.sh     # âœ¨ Init master + descarga imÃ¡genes
â”‚   â”œâ”€â”€ k3s-agent-init.sh      # âœ¨ Init workers + descarga imÃ¡genes
â”‚   â”œâ”€â”€ build-and-push.sh      # Build de imÃ¡genes Docker
â”‚   â””â”€â”€ deploy-to-k3s.sh       # Deploy de Coarlumini
â””â”€â”€ DEPLOYMENT-GUIDE.md        # Esta guÃ­a

coarlumini/
â”œâ”€â”€ k8s/                       # âœ¨ Manifiestos con local-path
â”‚   â”œâ”€â”€ 00-namespace.yaml
â”‚   â”œâ”€â”€ 01-configmap.yaml
â”‚   â”œâ”€â”€ 02-secrets.yaml
â”‚   â”œâ”€â”€ 03-database-pvc.yaml   # âœ… storageClassName: local-path
â”‚   â”œâ”€â”€ 04-database-deployment.yaml
â”‚   â”œâ”€â”€ 05-database-service.yaml
â”‚   â”œâ”€â”€ 06-backend-deployment.yaml
â”‚   â”œâ”€â”€ 07-backend-pvc.yaml    # âœ… storageClassName: local-path
â”‚   â”œâ”€â”€ 08-backend-service.yaml
â”‚   â”œâ”€â”€ 09-frontend-deployment.yaml
â”‚   â”œâ”€â”€ 10-frontend-pvc.yaml   # âœ… storageClassName: local-path
â”‚   â”œâ”€â”€ 11-nginx-config.yaml
â”‚   â”œâ”€â”€ 12-frontend-service.yaml
â”‚   â”œâ”€â”€ 13-ingress.yaml
â”‚   â””â”€â”€ 14-horizontal-escalling.yaml
â”œâ”€â”€ Dockerfile                 # Backend Laravel
â”œâ”€â”€ database/Dockerfile        # Database MySQL
â””â”€â”€ frontend/Dockerfile        # Frontend Vue.js
```

## âœ… Checklist de Deployment

Antes de ejecutar `terraform apply`, verifica:

- [ ] Herramientas instaladas (gcloud, docker, terraform)
- [ ] Autenticado con gcloud
- [ ] Docker configurado para GCR
- [ ] `terraform.tfvars` configurado con tu project_id
- [ ] APIs de GCP habilitadas
- [ ] Ejecutado `./scripts/validate-setup.sh` sin errores
- [ ] Tienes presupuesto suficiente (~$80-130/mes)

Una vez completado el deployment:

- [ ] Pods en estado `Running`
- [ ] PVCs en estado `Bound`
- [ ] ImÃ¡genes Docker en todos los nodos
- [ ] AplicaciÃ³n accesible desde el navegador
- [ ] Load Balancer funcionando

---

**Â¿Problemas?** Revisa la secciÃ³n de **SoluciÃ³n de Problemas** o ejecuta el script de diagnÃ³stico en el servidor:

```bash
gcloud compute ssh k3s-master-server --zone=us-central1-a
sudo kubectl get all -n coarlumini
sudo kubectl describe pods -n coarlumini
```

**Â¡Listo para deployar! ğŸš€**