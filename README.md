# Autoscaling Demo + Coarlumini K3s Integration

Esta es la integraciÃ³n completa de la infraestructura de autoscaling de Google Compute Engine con Kubernetes (K3s) para desplegar la aplicaciÃ³n Coarlumini.

## ğŸ¯ Â¿QuÃ© hace este proyecto?

Combina:
- âœ… **Infraestructura de autoscaling**: Load Balancer + Instance Group (2-5 instancias)
- âœ… **Cluster Kubernetes K3s**: 1 master + N workers (autoscaling)
- âœ… **AplicaciÃ³n Coarlumini**: Laravel + Vue.js + MySQL
- âœ… **Deployment automatizado**: Terraform provisioners que construyen y despliegan todo

## ğŸ—ï¸ Arquitectura

```
Internet
    â”‚
    â”œâ”€â”€â”€â”€â”€â”€> Load Balancer HTTP Global
    â”‚             â”‚
    â”‚             â”œâ”€â”€> K3s Agent 1 (Worker) â”€â”€â”
    â”‚             â”œâ”€â”€> K3s Agent 2 (Worker) â”€â”€â”¤ Autoscaling (2-5)
    â”‚             â””â”€â”€> K3s Agent N (Worker) â”€â”€â”¤
    â”‚                                          â”‚
    â””â”€â”€â”€â”€â”€â”€> K3s Server (Master - Fijo) â”€â”€â”€â”€â”€â”€â”˜
                  â”‚
                  â””â”€â”€> Kubernetes Cluster
                         â”œâ”€> MySQL Database
                         â”œâ”€> Laravel Backend  
                         â””â”€> Vue.js Frontend
```

### Componentes

1. **K3s Server (Master)**: Instancia fija `e2-medium` que controla el cluster
2. **K3s Agents (Workers)**: Grupo de autoscaling `e2-small` (2-5 instancias)
3. **Load Balancer**: Distribuye trÃ¡fico HTTP entre los workers
4. **Cloud Storage**: Almacena manifiestos de Kubernetes
5. **Container Registry**: Almacena imÃ¡genes Docker

## ğŸ“‹ Requisitos Previos

### Google Cloud Platform

1. **Proyecto de GCP** con facturaciÃ³n habilitada
2. **APIs habilitadas**:
   ```bash
   gcloud services enable compute.googleapis.com
   gcloud services enable storage.googleapis.com
   gcloud services enable containerregistry.googleapis.com
   ```

3. **AutenticaciÃ³n**:
   ```bash
   gcloud auth login
   gcloud config set project TU-PROJECT-ID
   ```

### Herramientas Locales

- [Terraform](https://www.terraform.io/downloads) o [OpenTofu](https://opentofu.org/) >= 1.6
- [gcloud CLI](https://cloud.google.com/sdk/docs/install)
- [Docker](https://docs.docker.com/get-docker/)

## ğŸš€ Deployment RÃ¡pido

### 1. Configurar Variables

Crea el archivo `terraform.tfvars`:

```hcl
project_id = "tu-proyecto-gcp"
region     = "us-central1"

# Opcional: personalizar configuraciÃ³n
k3s_server_machine_type = "e2-medium"  # Master: 2 vCPUs, 4GB RAM
agent_machine_type      = "e2-small"   # Workers: 2 vCPUs, 2GB RAM
min_replicas            = 2            # MÃ­nimo de workers
max_replicas            = 5            # MÃ¡ximo de workers
cpu_target              = 0.6          # 60% CPU para autoscalar
enable_auto_deploy      = true         # Deployment automÃ¡tico
deploy_wait_time        = 180          # Segundos de espera
```

### 2. Inicializar Terraform

```bash
cd autoscaling-demo
terraform init
```

### 3. Ver Plan de EjecuciÃ³n

```bash
terraform plan -var="project_id=tu-proyecto-gcp"
```

### 4. Desplegar Todo (Â¡Un Solo Comando!)

```bash
terraform apply -var="project_id=tu-proyecto-gcp"
```

**Esto automÃ¡ticamente:**
1. âœ… Crea infraestructura de red y firewall
2. âœ… Crea servidor K3s master
3. âœ… Crea grupo de autoscaling con workers K3s
4. âœ… Crea Load Balancer
5. âœ… Construye imÃ¡genes Docker de Coarlumini
6. âœ… Sube imÃ¡genes a Google Container Registry
7. âœ… Despliega Coarlumini en Kubernetes

**Tiempo estimado:** 12-15 minutos

### 5. Acceder a la AplicaciÃ³n

```bash
# Ver outputs de Terraform
terraform output

# Obtener URLs
terraform output access_urls
```

Accede a:
- **Load Balancer**: `http://<LOAD_BALANCER_IP>`
- **Directo al servidor**: `http://<SERVER_IP>:30080`

## ğŸ“Š Flujo de Deployment Detallado

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  1. terraform apply                                     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                  â”‚
      â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
      â”‚                       â”‚
      â–¼                       â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Infraestr.  â”‚    â”‚  K3s Server      â”‚
â”‚  - Network   â”‚    â”‚  - Instala K3s   â”‚
â”‚  - Firewall  â”‚    â”‚  - Descarga      â”‚
â”‚  - GCS       â”‚    â”‚    manifiestos   â”‚
â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
       â”‚                     â”‚
       â”‚    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
       â”‚    â”‚
       â–¼    â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  K3s Agents          â”‚
â”‚  - Instance Group    â”‚
â”‚  - Se unen al master â”‚
â”‚  - Autoscaling 2-5   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
           â”‚
           â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  2. Provisioner local-exec           â”‚
â”‚     (Espera 3 min)                   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
           â”‚
           â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  3. scripts/build-and-push.sh        â”‚
â”‚     - Construye 3 imÃ¡genes Docker    â”‚
â”‚     - Sube a GCR                     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
           â”‚
           â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  4. scripts/deploy-to-k3s.sh         â”‚
â”‚     - SSH al servidor K3s            â”‚
â”‚     - kubectl apply manifiestos      â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
           â”‚
           â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  âœ“ Coarlumini corriendo en K3s       â”‚
â”‚     - Database (MySQL)               â”‚
â”‚     - Backend (Laravel)              â”‚
â”‚     - Frontend (Vue.js)              â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

## ğŸ”§ GestiÃ³n y OperaciÃ³n

### SSH al Servidor K3s

```bash
# Usando gcloud
gcloud compute ssh k3s-master-server --zone=us-central1-a

# O usando el output de Terraform
terraform output ssh_commands
```

### Ver Estado del Cluster

```bash
# Dentro del servidor K3s
kubectl get nodes
kubectl get pods -n coarlumini
kubectl get services -n coarlumini
kubectl get all -n coarlumini
```

### Ver Logs de AplicaciÃ³n

```bash
# Logs del backend
kubectl logs -l app=coarlumini-backend -n coarlumini --tail=100 -f

# Logs del frontend
kubectl logs -l app=coarlumini-frontend -n coarlumini -f

# Logs de la base de datos
kubectl logs -l app=coarlumini-database -n coarlumini -f
```

### Escalar Componentes

#### Escalar Pods (HPA automÃ¡tico ya configurado)

```bash
# Escalar backend manualmente
kubectl scale deployment coarlumini-backend -n coarlumini --replicas=3

# Ver estado del HPA
kubectl get hpa -n coarlumini

# Describir HPA
kubectl describe hpa coarlumini-backend -n coarlumini
```

#### Escalar Instancias (Autoscaler de GCE)

```bash
# Ver instancias actuales
gcloud compute instance-groups managed list-instances web-group-manager \
    --zone=us-central1-a

# Cambiar lÃ­mites de autoscaling
gcloud compute instance-groups managed set-autoscaling web-group-manager \
    --zone=us-central1-a \
    --min-num-replicas=3 \
    --max-num-replicas=10
```

### Reiniciar Componentes

```bash
# Reiniciar backend
kubectl rollout restart deployment/coarlumini-backend -n coarlumini

# Ver progreso del rollout
kubectl rollout status deployment/coarlumini-backend -n coarlumini

# Reiniciar frontend
kubectl rollout restart deployment/coarlumini-frontend -n coarlumini
```

### Redesplegar AplicaciÃ³n

Si solo quieres redesplegar sin reconstruir infraestructura:

```bash
# OpciÃ³n 1: Desde tu mÃ¡quina local
cd autoscaling-demo
export PROJECT_ID="tu-proyecto"
export K3S_SERVER_NAME="k3s-master-server"
export ZONE="us-central1-a"

# Solo rebuild de imÃ¡genes
./scripts/build-and-push.sh

# Solo redeploy
./scripts/deploy-to-k3s.sh

# OpciÃ³n 2: Desde el servidor K3s
gcloud compute ssh k3s-master-server --zone=us-central1-a
sudo /root/deploy-coarlumini.sh
```

## ğŸ” Monitoreo

### Ver MÃ©tricas del Cluster

```bash
# En el servidor K3s
kubectl top nodes
kubectl top pods -n coarlumini
```

### Ver Eventos

```bash
# Eventos del namespace
kubectl get events -n coarlumini --sort-by='.lastTimestamp'

# Eventos de un pod especÃ­fico
kubectl describe pod <pod-name> -n coarlumini
```

### Ver Estado de Autoscaling

```bash
# Estado del autoscaler de GCE
gcloud compute instance-groups managed describe web-group-manager \
    --zone=us-central1-a

# HistÃ³rico de autoscaling
gcloud logging read "resource.type=gce_autoscaler" --limit 50
```

## ğŸ› ï¸ SoluciÃ³n de Problemas

### Pods no inician

```bash
# Ver estado detallado
kubectl describe pod <pod-name> -n coarlumini

# Ver eventos
kubectl get events -n coarlumini

# Verificar imÃ¡genes en GCR
gcloud container images list --repository=gcr.io/PROJECT_ID
```

### ImÃ¡genes no se descargan

```bash
# Verificar permisos del nodo
gcloud compute ssh <instance-name> --zone=us-central1-a
docker pull gcr.io/PROJECT_ID/coarlumini-backend:latest

# Re-autenticar Docker con GCR
gcloud auth configure-docker gcr.io
```

### Agentes no se unen al cluster

```bash
# Ver logs de startup del agente
gcloud compute instances get-serial-port-output <agent-name> \
    --zone=us-central1-a

# Verificar conectividad al master
gcloud compute ssh <agent-name> --zone=us-central1-a
curl -k https://<master-ip>:6443
```

### Base de datos no responde

```bash
# Ver logs de MySQL
kubectl logs -l app=coarlumini-database -n coarlumini

# Entrar al pod de database
kubectl exec -it <db-pod-name> -n coarlumini -- bash
mysql -u root -p
```

### Deployment automÃ¡tico fallÃ³

Si el provisioner fallÃ³, puedes ejecutar manualmente:

```bash
# Desde autoscaling-demo/
export PROJECT_ID="tu-proyecto"

# Build de imÃ¡genes
./scripts/build-and-push.sh

# Deploy
export K3S_SERVER_NAME="k3s-master-server"
export ZONE="us-central1-a"
./scripts/deploy-to-k3s.sh
```

## ğŸ” Seguridad

### Obtener Credenciales Sensibles

```bash
# Token K3s
terraform output k3s_token

# Password de Database
terraform output db_password

# Laravel App Key
terraform output app_key
```

### Configurar Kubeconfig Local

```bash
# Obtener kubeconfig del servidor
terraform output kubectl_config_command | bash

# O manualmente
gcloud compute ssh k3s-master-server --zone=us-central1-a \
  --command='sudo cat /etc/rancher/k3s/k3s.yaml' > kubeconfig.yaml

# Reemplazar 127.0.0.1 con la IP pÃºblica del servidor
SERVER_IP=$(terraform output -raw k3s_server_ip)
sed -i "s/127.0.0.1/$SERVER_IP/g" kubeconfig.yaml

# Usar kubeconfig
export KUBECONFIG=./kubeconfig.yaml
kubectl get nodes
```

## ğŸ“ Estructura de Archivos

```
autoscaling-demo/
â”œâ”€â”€ main.tf                          # Infraestructura principal con K3s
â”œâ”€â”€ variables.tf                     # Variables de configuraciÃ³n
â”œâ”€â”€ outputs.tf                       # Outputs (IPs, URLs, comandos)
â”œâ”€â”€ terraform.tfvars                 # TUS valores de configuraciÃ³n
â”œâ”€â”€ scripts/
â”‚   â”œâ”€â”€ k3s-server-init.sh          # InicializaciÃ³n del master K3s
â”‚   â”œâ”€â”€ k3s-agent-init.sh           # InicializaciÃ³n de workers K3s
â”‚   â”œâ”€â”€ build-and-push.sh           # Build de imÃ¡genes Docker
â”‚   â””â”€â”€ deploy-to-k3s.sh            # Deploy de la aplicaciÃ³n
â”œâ”€â”€ *-original.tf.backup            # Backups de archivos originales
â””â”€â”€ README.md                        # Este archivo

coarlumini/                          # (Sin cambios)
â”œâ”€â”€ k8s/                            # Manifiestos Kubernetes (reutilizados)
â”œâ”€â”€ frontend/                       # Frontend Vue.js
â”œâ”€â”€ database/                       # Database MySQL
â”œâ”€â”€ Dockerfile                      # Backend Laravel
â””â”€â”€ ...
```

## ğŸ§¹ Limpieza

### Destruir Toda la Infraestructura

```bash
cd autoscaling-demo
terraform destroy -var="project_id=tu-proyecto-gcp"
```

### Solo Eliminar la AplicaciÃ³n (mantener infraestructura)

```bash
gcloud compute ssh k3s-master-server --zone=us-central1-a
kubectl delete namespace coarlumini
```

## ğŸ’° EstimaciÃ³n de Costos

Con configuraciÃ³n por defecto en `us-central1`:

| Recurso | Tipo | Costo/mes (aprox) |
|---------|------|-------------------|
| K3s Server | e2-medium (siempre activo) | ~$24 |
| K3s Agents | 2-5 x e2-small | ~$24-60 |
| Load Balancer | HTTP Global | ~$18 |
| Discos persistentes | 50GB + 30GB x agents | ~$10-20 |
| Egreso de red | Variable | ~$5-10 |
| **TOTAL** | | **$81-132/mes** |

> ğŸ’¡ **Tip**: Para reducir costos en desarrollo, usa `min_replicas=1` y `max_replicas=2`

## ğŸ”„ Actualizar la AplicaciÃ³n

### Actualizar CÃ³digo de Coarlumini

```bash
# 1. Actualizar cÃ³digo en ../coarlumini/
# 2. Reconstruir imÃ¡genes
cd autoscaling-demo
export PROJECT_ID="tu-proyecto"
./scripts/build-and-push.sh

# 3. Redesplegar
export K3S_SERVER_NAME="k3s-master-server"
export ZONE="us-central1-a"
./scripts/deploy-to-k3s.sh
```

### Actualizar Manifiestos K8s

```bash
# 1. Editar manifiestos en ../coarlumini/k8s/
# 2. Re-aplicar con Terraform (sube a GCS)
terraform apply -var="project_id=tu-proyecto"

# 3. Aplicar en el cluster
gcloud compute ssh k3s-master-server --zone=us-central1-a
cd /root/k8s-manifests
gsutil -m cp -r "gs://BUCKET_NAME/*" .
kubectl apply -f . -n coarlumini
```

## ğŸ“š Referencias

- [K3s Documentation](https://docs.k3s.io/)
- [Terraform GCP Provider](https://registry.terraform.io/providers/hashicorp/google/latest/docs)
- [GCE Autoscaling](https://cloud.google.com/compute/docs/autoscaler)
- [Kubernetes Documentation](https://kubernetes.io/docs/)
- [Google Container Registry](https://cloud.google.com/container-registry/docs)

## ğŸ¤ Contribuir

Este proyecto integra:
- Infraestructura base de `autoscaling-demo`
- AplicaciÃ³n de `coarlumini`

Para modificar:
1. **Infraestructura**: Edita archivos `.tf`
2. **Scripts**: Edita archivos en `scripts/`
3. **AplicaciÃ³n**: Edita archivos en `../coarlumini/`

## âš ï¸ Notas Importantes

1. **Primera ejecuciÃ³n**: El primer `terraform apply` tarda ~12-15 minutos
2. **Credenciales**: Las credenciales sensibles se generan automÃ¡ticamente
3. **Persistencia**: Los datos de MySQL persisten en discos (sobreviven recreaciones)
4. **Autoscaling**: Funciona a dos niveles:
   - **Pods**: HPA escala rÃ©plicas segÃºn CPU
   - **Instancias**: Autoscaler de GCE escala workers segÃºn carga
5. **Health checks**: Nginx en puerto 80 para que el LB detecte instancias sanas

## ğŸ“ Aprendizajes

Este proyecto demuestra:
- âœ… Infrastructure as Code con Terraform/OpenTofu
- âœ… Kubernetes en infraestructura de autoscaling
- âœ… Multi-tier application deployment
- âœ… CI/CD con Terraform provisioners
- âœ… Container registry y Docker builds
- âœ… Load balancing y autoscaling en GCP
- âœ… GestiÃ³n de secretos con Terraform random providers

---

**Â¿Problemas?** Revisa la secciÃ³n de [SoluciÃ³n de Problemas](#-soluciÃ³n-de-problemas)

**Â¿Preguntas?** Revisa los [outputs de Terraform](#5-acceder-a-la-aplicaciÃ³n) para comandos Ãºtiles